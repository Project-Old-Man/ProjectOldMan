"""
ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
"""
import subprocess
import sys
import os

def install_package(package, extra_index_url=None):
    """íŒ¨í‚¤ì§€ ì„¤ì¹˜"""
    cmd = [sys.executable, "-m", "pip", "install", package]
    if extra_index_url:
        cmd.extend(["--extra-index-url", extra_index_url])
    
    try:
        print(f"ğŸ“¦ {package} ì„¤ì¹˜ ì¤‘...")
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print(f"âœ… {package} ì„¤ì¹˜ ì™„ë£Œ!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {package} ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
        print(f"stdout: {e.stdout}")
        print(f"stderr: {e.stderr}")
        return False

def main():
    print("ğŸš€ ProjectOldMan ë°±ì—”ë“œ ì˜ì¡´ì„± ì„¤ì¹˜ ì‹œì‘...")
    
    # ê¸°ë³¸ íŒ¨í‚¤ì§€ë“¤
    basic_packages = [
        "fastapi==0.104.1",
        "uvicorn==0.24.0", 
        "pydantic==2.5.0",
        "python-multipart==0.0.6",
        "numpy==1.24.3",
        "sentence-transformers==2.2.2",
        "faiss-cpu==1.7.4",
        "torch==2.1.0",
        "transformers==4.35.0",
        "python-dotenv==1.0.0"
    ]
    
    # ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
    for package in basic_packages:
        install_package(package)
    
    # llama-cpp-python ì„¤ì¹˜ (CPU ìµœì í™”)
    print("\nğŸ¤– llama-cpp-python ì„¤ì¹˜ ì¤‘ (CPU ìµœì í™”)...")
    llama_success = install_package(
        "llama-cpp-python==0.2.20",
        "https://abetlen.github.io/llama-cpp-python/whl/cpu"
    )
    
    if not llama_success:
        print("âš ï¸ CPU ìµœì í™” ë²„ì „ ì„¤ì¹˜ ì‹¤íŒ¨, ê¸°ë³¸ ë²„ì „ ì‹œë„...")
        install_package("llama-cpp-python==0.2.20")
    
    print("\nğŸ‰ ëª¨ë“  ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ!")
    print("ğŸ’¡ ì´ì œ 'python main.py'ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
