import logging
from typing import List, Dict, Any
import os

logger = logging.getLogger(__name__)

class VectorStore:
    def __init__(self, embedding_service):
        self.embedding_service = embedding_service
        self.use_faiss = False
        self.index = None
        self.documents = []
        self.document_metadata = []
        
        # ì‹¤ì œ FAISS ì´ˆê¸°í™” ì‹œë„
        logger.info("ğŸ”„ FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹œë„...")
        self._init_faiss()
    
    def _init_faiss(self):
        """FAISS ì´ˆê¸°í™” (ì‹¤íŒ¨ ì‹œ ê°„ë‹¨ ì €ì¥ì†Œ ì‚¬ìš©)"""
        try:
            import faiss
            import numpy as np
            logger.info("ğŸ“š FAISS ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ë¨")
            
            # FAISS ì¸ë±ìŠ¤ ìƒì„± (768ì°¨ì›ìœ¼ë¡œ ì„¤ì •)
            dimension = self.embedding_service.get_embedding_dim()
            self.index = faiss.IndexFlatIP(dimension)  # Inner Product (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
            self.use_faiss = True
            
            logger.info(f"âœ… FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (ì°¨ì›: {dimension})")
            
        except Exception as e:
            logger.warning(f"âš ï¸ FAISS ì´ˆê¸°í™” ì‹¤íŒ¨, ê°„ë‹¨ ë²¡í„° ì €ì¥ì†Œ ì‚¬ìš©: {e}")
            self.use_faiss = False
    
    def add_documents(self, texts: List[str], metadata: List[Dict[str, Any]]):
        """ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€"""
        try:
            logger.info(f"ğŸ“ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— {len(texts)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì¤‘...")
            
            # ì‹¤ì œ ì„ë² ë”© ìƒì„± (ì´ë¯¸ normalize_embeddings=Trueë¡œ ì •ê·œí™”ë¨)
            embeddings = self.embedding_service.encode(texts)
            
            if self.use_faiss and embeddings:
                try:
                    import numpy as np
                    import faiss
                    
                    embeddings_array = np.array(embeddings, dtype=np.float32)
                    
                    # ì„ë² ë”©ì´ ì´ë¯¸ ì •ê·œí™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì •ê·œí™” ë¶ˆí•„ìš”
                    # (normalize_embeddings=Trueë¡œ ì¸í•´ ì´ë¯¸ L2 ì •ê·œí™”ë¨)
                    
                    # FAISS ì¸ë±ìŠ¤ì— ì¶”ê°€
                    self.index.add(embeddings_array)
                    logger.info("âœ… FAISS ì¸ë±ìŠ¤ì— ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ FAISS ì¶”ê°€ ì‹¤íŒ¨: {e}")
            
            # ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
            self.documents.extend(texts)
            self.document_metadata.extend(metadata)
            
            logger.info(f"âœ… {len(texts)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            raise e
    
    def search(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            if len(self.documents) == 0:
                logger.warning("âš ï¸ ì €ì¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            logger.info(f"ğŸ” ë²¡í„° ê²€ìƒ‰: '{query[:30]}...' (top_k={top_k})")
            
            # ì‹¤ì œ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_service.encode([query])
            if not query_embedding:
                logger.error("âŒ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return []
            
            query_vec = query_embedding[0]
            
            if self.use_faiss and self.index:
                try:
                    results = self._faiss_search(query_vec, top_k)
                    if results:
                        logger.info(f"âœ… FAISS ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                        return results
                except Exception as e:
                    logger.warning(f"âš ï¸ FAISS ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            
            # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ (Fallback)
            results = self._simple_similarity_search(query_vec, top_k)
            logger.info(f"âœ… ê°„ë‹¨ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _faiss_search(self, query_vec: List[float], top_k: int) -> List[Dict[str, Any]]:
        """FAISSë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰"""
        import numpy as np
        import faiss
        
        query_array = np.array([query_vec], dtype=np.float32)
        # ì¿¼ë¦¬ ì„ë² ë”©ë„ ì´ë¯¸ ì •ê·œí™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì •ê·œí™” ë¶ˆí•„ìš”
        
        # FAISS ê²€ìƒ‰
        scores, indices = self.index.search(query_array, min(top_k, len(self.documents)))
        
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx < len(self.documents) and idx >= 0:
                results.append({
                    "text": self.documents[idx],
                    "metadata": self.document_metadata[idx],
                    "score": float(score),
                    "rank": i + 1,
                    "search_type": "faiss"
                })
        
        return results
    
    def _simple_similarity_search(self, query_embedding: List[float], top_k: int) -> List[Dict[str, Any]]:
        """ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ (ì‹¤ì œ ì„ë² ë”© ì‚¬ìš©)"""
        similarities = []
        
        # ëª¨ë“  ë¬¸ì„œì™€ ìœ ì‚¬ë„ ê³„ì‚°
        for i, doc in enumerate(self.documents):
            try:
                doc_embeddings = self.embedding_service.encode([doc])
                if doc_embeddings:
                    doc_embedding = doc_embeddings[0]
                    similarity = self._cosine_similarity(query_embedding, doc_embedding)
                    similarities.append((similarity, i))
            except Exception as e:
                logger.warning(f"âš ï¸ ë¬¸ì„œ {i} ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                similarities.append((0.0, i))
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        similarities.sort(reverse=True)
        
        # ìƒìœ„ kê°œ ê²°ê³¼ ë°˜í™˜
        results = []
        for rank, (score, idx) in enumerate(similarities[:top_k]):
            results.append({
                "text": self.documents[idx],
                "metadata": self.document_metadata[idx],
                "score": float(score),
                "rank": rank + 1,
                "search_type": "simple"
            })
        
        return results
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            dot_product = sum(a * b for a, b in zip(vec1, vec2))
            norm1 = sum(a * a for a in vec1) ** 0.5
            norm2 = sum(b * b for b in vec2) ** 0.5
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            return dot_product / (norm1 * norm2)
        except:
            return 0.0
    
    def get_stats(self) -> Dict[str, Any]:
        """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ë°˜í™˜"""
        return {
            "total_documents": len(self.documents),
            "embedding_dimension": self.embedding_service.get_embedding_dim(),
            "using_faiss": self.use_faiss,
            "using_real_embeddings": self.embedding_service.is_using_real_model(),
            "embedding_status": self.embedding_service.get_status()
        }

